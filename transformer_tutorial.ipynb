{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short notebook to walk through some of the applications of Transformer neural nets for tokenized analytic data, and demonstrate the functionality of the repo through examples. First let's load in the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Dataset' from 'torch' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mencoder_decoder\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mencoder_only\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mdecoder_only\u001b[39;00m\n",
      "File \u001b[0;32m~/repos_physics/transformer-boilerplate/encoder_only.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, Dataloader\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define Dataset Class\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSequenceDataset\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Dataset' from 'torch' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/__init__.py)"
     ]
    }
   ],
   "source": [
    "import encoder_decoder, encoder_only, decoder_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each architecture does something a little different, roughly, the inputs and outputs look like the following:\n",
    "\n",
    "1. Encoder-Only: [3,4,2,5,...,5,6,3,4,3,3] --> 8\n",
    "2. Decoder-Only: [[5,6,3,4,3,3],[8,2,3,5,1,3],...]\n",
    "3. Encoder-Decoder: [5,6,3,4,3,3] --> [3,4,2,5,1,3,2]\n",
    "\n",
    "In words, this looks like:\n",
    "\n",
    "1. Encoders take a sequence and maps it to a new vector in the embedding space that gets mapped to a single category\n",
    "2. Decoders take a sequence and predict the next token, it is thus trained on a set of sequences\n",
    "3. Encoder-Decoder conditions the next token predictino of the decoder layers with an encoder output vector. \n",
    "\n",
    "Obviously, these are all overlappping, and in many ways you can create the same behavior for encoders with decoders and vice-versa (just have the output of encoder map to the next token in the sequence, as opposed to some completely different semantic category). \n",
    "\n",
    "But for historical reasons, we'll keep all three of these architectures distinct as they have been used for different types of token prediction tasks.\n",
    "\n",
    "Let's start with encoder only and \"train\" a neural network to identify the largest token in a sequence -- i.e. effectively implement a MAX function acting on list using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Class\n",
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "tgt = []\n",
    "import random\n",
    "\n",
    "for i in range(20):\n",
    "    start = []\n",
    "    for j in range(7):\n",
    "        start.append(random.randint(1,10))\n",
    "    seq.append(start)\n",
    "    tgt.append(random.randint(1,20))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = SequenceDataset(seq,tgt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9.7131e-01,  6.4653e-01,  1.1058e+00, -1.5218e+00, -2.9165e-01,\n",
       "         1.7518e-01, -6.2922e-02, -1.3742e+00,  5.7713e-01,  9.7474e-02,\n",
       "        -5.5063e-01, -4.2551e-01, -2.4405e+00,  3.3425e-01, -9.2217e-01,\n",
       "         2.9956e-02, -1.7427e+00, -2.9713e-04,  2.0554e+00, -3.3534e-01,\n",
       "         4.4978e-01, -1.4612e+00, -9.6993e-01, -1.7550e+00, -4.9043e-01,\n",
       "         2.1186e-01, -2.5202e+00, -3.3610e-01, -6.8310e-01, -3.2452e-02,\n",
       "         2.7511e+00, -9.1493e-01,  1.3785e-01,  1.0419e+00, -1.4911e+00,\n",
       "         3.2904e-01,  4.1584e-02,  1.4884e-01,  2.4676e-01,  1.1247e+00,\n",
       "         1.3813e+00, -1.2214e-01,  1.9641e-01,  4.9167e-01,  2.5802e-01,\n",
       "         3.2950e-01,  1.3350e+00,  1.0029e+00,  9.8470e-01, -8.4471e-01,\n",
       "         1.3989e+00,  7.9151e-01,  2.5862e-01, -1.2320e+00,  8.8090e-02,\n",
       "        -4.4815e-01,  7.1815e-02,  5.7713e-01,  1.3305e+00,  1.1457e+00,\n",
       "        -2.8976e-01, -1.2213e-01, -1.1351e+00,  9.9267e-01, -1.4445e+00,\n",
       "         1.2487e+00, -1.0512e+00,  9.6878e-01, -1.2321e-02,  1.4471e+00,\n",
       "        -4.3862e-01, -1.9809e-01, -1.2566e+00,  1.7317e-01,  1.7531e+00,\n",
       "         4.2993e-02,  1.4002e+00, -9.4054e-01,  4.3514e-01,  9.2138e-01,\n",
       "        -1.2417e+00,  9.7616e-01,  1.1048e+00, -1.9091e-02, -2.9976e-01,\n",
       "        -1.5694e+00, -5.5724e-01, -1.8868e-01, -1.4834e-01,  6.9024e-01,\n",
       "        -6.8212e-01, -1.1697e+00,  7.9146e-01,  1.3544e+00,  6.0817e-01,\n",
       "        -1.3502e+00], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=96,nhead=8)\n",
    "encoder_only = nn.TransformerEncoder(encoder_layer,num_layers=4)\n",
    "src = torch.rand(4,4,96)\n",
    "out = encoder_only(src)\n",
    "out[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[ 1, 10,  6,  7,  3,  6,  7],\n",
      "        [ 8,  6,  4,  2, 10,  9,  6],\n",
      "        [ 1,  8,  4,  7,  8,  8,  7],\n",
      "        [ 8,  6,  1,  9,  3,  6,  9],\n",
      "        [ 5,  8,  1,  3,  7,  1,  8]]) tensor([[ 1,  8,  1,  8,  5],\n",
      "        [10,  6,  8,  6,  8],\n",
      "        [ 6,  4,  4,  1,  1],\n",
      "        [ 7,  2,  7,  9,  3],\n",
      "        [ 3, 10,  8,  3,  7],\n",
      "        [ 6,  9,  8,  6,  1],\n",
      "        [ 7,  6,  7,  9,  8]]) tensor([[ 1,  8,  1,  8,  5],\n",
      "        [10,  6,  8,  6,  8],\n",
      "        [ 6,  4,  4,  1,  1],\n",
      "        [ 7,  2,  7,  9,  3],\n",
      "        [ 3, 10,  8,  3,  7],\n",
      "        [ 6,  9,  8,  6,  1],\n",
      "        [ 7,  6,  7,  9,  8]])\n",
      "tensor([[ 2,  3,  3, 10,  7,  9,  3],\n",
      "        [ 7,  3,  6,  5,  1,  3,  2],\n",
      "        [ 9,  2,  9,  6, 10,  5,  8],\n",
      "        [ 7, 10, 10,  5,  3,  4,  1],\n",
      "        [ 3,  2,  8, 10,  3, 10,  9]]) tensor([[ 2,  7,  9,  7,  3],\n",
      "        [ 3,  3,  2, 10,  2],\n",
      "        [ 3,  6,  9, 10,  8],\n",
      "        [10,  5,  6,  5, 10],\n",
      "        [ 7,  1, 10,  3,  3],\n",
      "        [ 9,  3,  5,  4, 10],\n",
      "        [ 3,  2,  8,  1,  9]]) tensor([[ 2,  7,  9,  7,  3],\n",
      "        [ 3,  3,  2, 10,  2],\n",
      "        [ 3,  6,  9, 10,  8],\n",
      "        [10,  5,  6,  5, 10],\n",
      "        [ 7,  1, 10,  3,  3],\n",
      "        [ 9,  3,  5,  4, 10],\n",
      "        [ 3,  2,  8,  1,  9]])\n",
      "tensor([[ 5,  2,  7,  5,  8, 10,  6],\n",
      "        [10,  9,  5,  9,  1,  6, 10],\n",
      "        [ 1,  8,  1,  9,  9,  4,  9],\n",
      "        [ 2,  6,  9,  7,  1,  4,  5],\n",
      "        [ 2,  9,  2,  4,  7,  6,  5]]) tensor([[ 5, 10,  1,  2,  2],\n",
      "        [ 2,  9,  8,  6,  9],\n",
      "        [ 7,  5,  1,  9,  2],\n",
      "        [ 5,  9,  9,  7,  4],\n",
      "        [ 8,  1,  9,  1,  7],\n",
      "        [10,  6,  4,  4,  6],\n",
      "        [ 6, 10,  9,  5,  5]]) tensor([[ 5, 10,  1,  2,  2],\n",
      "        [ 2,  9,  8,  6,  9],\n",
      "        [ 7,  5,  1,  9,  2],\n",
      "        [ 5,  9,  9,  7,  4],\n",
      "        [ 8,  1,  9,  1,  7],\n",
      "        [10,  6,  4,  4,  6],\n",
      "        [ 6, 10,  9,  5,  5]])\n",
      "tensor([[ 2,  3,  9,  7,  1,  3,  4],\n",
      "        [ 3,  3,  8,  5,  7, 10, 10],\n",
      "        [ 1,  7,  8,  7,  1,  2,  6],\n",
      "        [ 9,  3,  2,  1,  3, 10,  5],\n",
      "        [ 8, 10,  7,  5,  9, 10,  2]]) tensor([[ 2,  3,  1,  9,  8],\n",
      "        [ 3,  3,  7,  3, 10],\n",
      "        [ 9,  8,  8,  2,  7],\n",
      "        [ 7,  5,  7,  1,  5],\n",
      "        [ 1,  7,  1,  3,  9],\n",
      "        [ 3, 10,  2, 10, 10],\n",
      "        [ 4, 10,  6,  5,  2]]) tensor([[ 2,  3,  1,  9,  8],\n",
      "        [ 3,  3,  7,  3, 10],\n",
      "        [ 9,  8,  8,  2,  7],\n",
      "        [ 7,  5,  7,  1,  5],\n",
      "        [ 1,  7,  1,  3,  9],\n",
      "        [ 3, 10,  2, 10, 10],\n",
      "        [ 4, 10,  6,  5,  2]])\n",
      "1\n",
      "tensor([[ 3,  3,  8,  5,  7, 10, 10],\n",
      "        [ 2,  3,  9,  7,  1,  3,  4],\n",
      "        [ 9,  2,  9,  6, 10,  5,  8],\n",
      "        [ 2,  3,  3, 10,  7,  9,  3],\n",
      "        [ 1,  7,  8,  7,  1,  2,  6]]) tensor([[ 3,  2,  9,  2,  1],\n",
      "        [ 3,  3,  2,  3,  7],\n",
      "        [ 8,  9,  9,  3,  8],\n",
      "        [ 5,  7,  6, 10,  7],\n",
      "        [ 7,  1, 10,  7,  1],\n",
      "        [10,  3,  5,  9,  2],\n",
      "        [10,  4,  8,  3,  6]]) tensor([[ 3,  2,  9,  2,  1],\n",
      "        [ 3,  3,  2,  3,  7],\n",
      "        [ 8,  9,  9,  3,  8],\n",
      "        [ 5,  7,  6, 10,  7],\n",
      "        [ 7,  1, 10,  7,  1],\n",
      "        [10,  3,  5,  9,  2],\n",
      "        [10,  4,  8,  3,  6]])\n",
      "tensor([[ 1,  8,  1,  9,  9,  4,  9],\n",
      "        [ 3,  2,  8, 10,  3, 10,  9],\n",
      "        [ 7, 10, 10,  5,  3,  4,  1],\n",
      "        [ 5,  8,  1,  3,  7,  1,  8],\n",
      "        [ 2,  6,  9,  7,  1,  4,  5]]) tensor([[ 1,  3,  7,  5,  2],\n",
      "        [ 8,  2, 10,  8,  6],\n",
      "        [ 1,  8, 10,  1,  9],\n",
      "        [ 9, 10,  5,  3,  7],\n",
      "        [ 9,  3,  3,  7,  1],\n",
      "        [ 4, 10,  4,  1,  4],\n",
      "        [ 9,  9,  1,  8,  5]]) tensor([[ 1,  3,  7,  5,  2],\n",
      "        [ 8,  2, 10,  8,  6],\n",
      "        [ 1,  8, 10,  1,  9],\n",
      "        [ 9, 10,  5,  3,  7],\n",
      "        [ 9,  3,  3,  7,  1],\n",
      "        [ 4, 10,  4,  1,  4],\n",
      "        [ 9,  9,  1,  8,  5]])\n",
      "tensor([[ 1, 10,  6,  7,  3,  6,  7],\n",
      "        [ 5,  2,  7,  5,  8, 10,  6],\n",
      "        [ 1,  8,  4,  7,  8,  8,  7],\n",
      "        [10,  9,  5,  9,  1,  6, 10],\n",
      "        [ 8, 10,  7,  5,  9, 10,  2]]) tensor([[ 1,  5,  1, 10,  8],\n",
      "        [10,  2,  8,  9, 10],\n",
      "        [ 6,  7,  4,  5,  7],\n",
      "        [ 7,  5,  7,  9,  5],\n",
      "        [ 3,  8,  8,  1,  9],\n",
      "        [ 6, 10,  8,  6, 10],\n",
      "        [ 7,  6,  7, 10,  2]]) tensor([[ 1,  5,  1, 10,  8],\n",
      "        [10,  2,  8,  9, 10],\n",
      "        [ 6,  7,  4,  5,  7],\n",
      "        [ 7,  5,  7,  9,  5],\n",
      "        [ 3,  8,  8,  1,  9],\n",
      "        [ 6, 10,  8,  6, 10],\n",
      "        [ 7,  6,  7, 10,  2]])\n",
      "tensor([[ 9,  3,  2,  1,  3, 10,  5],\n",
      "        [ 8,  6,  4,  2, 10,  9,  6],\n",
      "        [ 7,  3,  6,  5,  1,  3,  2],\n",
      "        [ 8,  6,  1,  9,  3,  6,  9],\n",
      "        [ 2,  9,  2,  4,  7,  6,  5]]) tensor([[ 9,  8,  7,  8,  2],\n",
      "        [ 3,  6,  3,  6,  9],\n",
      "        [ 2,  4,  6,  1,  2],\n",
      "        [ 1,  2,  5,  9,  4],\n",
      "        [ 3, 10,  1,  3,  7],\n",
      "        [10,  9,  3,  6,  6],\n",
      "        [ 5,  6,  2,  9,  5]]) tensor([[ 9,  8,  7,  8,  2],\n",
      "        [ 3,  6,  3,  6,  9],\n",
      "        [ 2,  4,  6,  1,  2],\n",
      "        [ 1,  2,  5,  9,  4],\n",
      "        [ 3, 10,  1,  3,  7],\n",
      "        [10,  9,  3,  6,  6],\n",
      "        [ 5,  6,  2,  9,  5]])\n",
      "2\n",
      "tensor([[ 2,  3,  3, 10,  7,  9,  3],\n",
      "        [ 2,  6,  9,  7,  1,  4,  5],\n",
      "        [ 3,  3,  8,  5,  7, 10, 10],\n",
      "        [ 1,  8,  1,  9,  9,  4,  9],\n",
      "        [ 8,  6,  1,  9,  3,  6,  9]]) tensor([[ 2,  2,  3,  1,  8],\n",
      "        [ 3,  6,  3,  8,  6],\n",
      "        [ 3,  9,  8,  1,  1],\n",
      "        [10,  7,  5,  9,  9],\n",
      "        [ 7,  1,  7,  9,  3],\n",
      "        [ 9,  4, 10,  4,  6],\n",
      "        [ 3,  5, 10,  9,  9]]) tensor([[ 2,  2,  3,  1,  8],\n",
      "        [ 3,  6,  3,  8,  6],\n",
      "        [ 3,  9,  8,  1,  1],\n",
      "        [10,  7,  5,  9,  9],\n",
      "        [ 7,  1,  7,  9,  3],\n",
      "        [ 9,  4, 10,  4,  6],\n",
      "        [ 3,  5, 10,  9,  9]])\n",
      "tensor([[ 1, 10,  6,  7,  3,  6,  7],\n",
      "        [ 9,  2,  9,  6, 10,  5,  8],\n",
      "        [ 2,  3,  9,  7,  1,  3,  4],\n",
      "        [ 3,  2,  8, 10,  3, 10,  9],\n",
      "        [ 2,  9,  2,  4,  7,  6,  5]]) tensor([[ 1,  9,  2,  3,  2],\n",
      "        [10,  2,  3,  2,  9],\n",
      "        [ 6,  9,  9,  8,  2],\n",
      "        [ 7,  6,  7, 10,  4],\n",
      "        [ 3, 10,  1,  3,  7],\n",
      "        [ 6,  5,  3, 10,  6],\n",
      "        [ 7,  8,  4,  9,  5]]) tensor([[ 1,  9,  2,  3,  2],\n",
      "        [10,  2,  3,  2,  9],\n",
      "        [ 6,  9,  9,  8,  2],\n",
      "        [ 7,  6,  7, 10,  4],\n",
      "        [ 3, 10,  1,  3,  7],\n",
      "        [ 6,  5,  3, 10,  6],\n",
      "        [ 7,  8,  4,  9,  5]])\n",
      "tensor([[ 1,  7,  8,  7,  1,  2,  6],\n",
      "        [ 8,  6,  4,  2, 10,  9,  6],\n",
      "        [ 7, 10, 10,  5,  3,  4,  1],\n",
      "        [10,  9,  5,  9,  1,  6, 10],\n",
      "        [ 8, 10,  7,  5,  9, 10,  2]]) tensor([[ 1,  8,  7, 10,  8],\n",
      "        [ 7,  6, 10,  9, 10],\n",
      "        [ 8,  4, 10,  5,  7],\n",
      "        [ 7,  2,  5,  9,  5],\n",
      "        [ 1, 10,  3,  1,  9],\n",
      "        [ 2,  9,  4,  6, 10],\n",
      "        [ 6,  6,  1, 10,  2]]) tensor([[ 1,  8,  7, 10,  8],\n",
      "        [ 7,  6, 10,  9, 10],\n",
      "        [ 8,  4, 10,  5,  7],\n",
      "        [ 7,  2,  5,  9,  5],\n",
      "        [ 1, 10,  3,  1,  9],\n",
      "        [ 2,  9,  4,  6, 10],\n",
      "        [ 6,  6,  1, 10,  2]])\n",
      "tensor([[ 9,  3,  2,  1,  3, 10,  5],\n",
      "        [ 1,  8,  4,  7,  8,  8,  7],\n",
      "        [ 5,  8,  1,  3,  7,  1,  8],\n",
      "        [ 5,  2,  7,  5,  8, 10,  6],\n",
      "        [ 7,  3,  6,  5,  1,  3,  2]]) tensor([[ 9,  1,  5,  5,  7],\n",
      "        [ 3,  8,  8,  2,  3],\n",
      "        [ 2,  4,  1,  7,  6],\n",
      "        [ 1,  7,  3,  5,  5],\n",
      "        [ 3,  8,  7,  8,  1],\n",
      "        [10,  8,  1, 10,  3],\n",
      "        [ 5,  7,  8,  6,  2]]) tensor([[ 9,  1,  5,  5,  7],\n",
      "        [ 3,  8,  8,  2,  3],\n",
      "        [ 2,  4,  1,  7,  6],\n",
      "        [ 1,  7,  3,  5,  5],\n",
      "        [ 3,  8,  7,  8,  1],\n",
      "        [10,  8,  1, 10,  3],\n",
      "        [ 5,  7,  8,  6,  2]])\n",
      "3\n",
      "tensor([[ 2,  3,  3, 10,  7,  9,  3],\n",
      "        [ 1,  8,  1,  9,  9,  4,  9],\n",
      "        [ 1, 10,  6,  7,  3,  6,  7],\n",
      "        [ 1,  8,  4,  7,  8,  8,  7],\n",
      "        [ 2,  6,  9,  7,  1,  4,  5]]) tensor([[ 2,  1,  1,  1,  2],\n",
      "        [ 3,  8, 10,  8,  6],\n",
      "        [ 3,  1,  6,  4,  9],\n",
      "        [10,  9,  7,  7,  7],\n",
      "        [ 7,  9,  3,  8,  1],\n",
      "        [ 9,  4,  6,  8,  4],\n",
      "        [ 3,  9,  7,  7,  5]]) tensor([[ 2,  1,  1,  1,  2],\n",
      "        [ 3,  8, 10,  8,  6],\n",
      "        [ 3,  1,  6,  4,  9],\n",
      "        [10,  9,  7,  7,  7],\n",
      "        [ 7,  9,  3,  8,  1],\n",
      "        [ 9,  4,  6,  8,  4],\n",
      "        [ 3,  9,  7,  7,  5]])\n",
      "tensor([[ 9,  2,  9,  6, 10,  5,  8],\n",
      "        [ 2,  3,  9,  7,  1,  3,  4],\n",
      "        [ 7,  3,  6,  5,  1,  3,  2],\n",
      "        [ 7, 10, 10,  5,  3,  4,  1],\n",
      "        [ 8, 10,  7,  5,  9, 10,  2]]) tensor([[ 9,  2,  7,  7,  8],\n",
      "        [ 2,  3,  3, 10, 10],\n",
      "        [ 9,  9,  6, 10,  7],\n",
      "        [ 6,  7,  5,  5,  5],\n",
      "        [10,  1,  1,  3,  9],\n",
      "        [ 5,  3,  3,  4, 10],\n",
      "        [ 8,  4,  2,  1,  2]]) tensor([[ 9,  2,  7,  7,  8],\n",
      "        [ 2,  3,  3, 10, 10],\n",
      "        [ 9,  9,  6, 10,  7],\n",
      "        [ 6,  7,  5,  5,  5],\n",
      "        [10,  1,  1,  3,  9],\n",
      "        [ 5,  3,  3,  4, 10],\n",
      "        [ 8,  4,  2,  1,  2]])\n",
      "tensor([[ 8,  6,  1,  9,  3,  6,  9],\n",
      "        [10,  9,  5,  9,  1,  6, 10],\n",
      "        [ 5,  8,  1,  3,  7,  1,  8],\n",
      "        [ 5,  2,  7,  5,  8, 10,  6],\n",
      "        [ 2,  9,  2,  4,  7,  6,  5]]) tensor([[ 8, 10,  5,  5,  2],\n",
      "        [ 6,  9,  8,  2,  9],\n",
      "        [ 1,  5,  1,  7,  2],\n",
      "        [ 9,  9,  3,  5,  4],\n",
      "        [ 3,  1,  7,  8,  7],\n",
      "        [ 6,  6,  1, 10,  6],\n",
      "        [ 9, 10,  8,  6,  5]]) tensor([[ 8, 10,  5,  5,  2],\n",
      "        [ 6,  9,  8,  2,  9],\n",
      "        [ 1,  5,  1,  7,  2],\n",
      "        [ 9,  9,  3,  5,  4],\n",
      "        [ 3,  1,  7,  8,  7],\n",
      "        [ 6,  6,  1, 10,  6],\n",
      "        [ 9, 10,  8,  6,  5]])\n",
      "tensor([[ 8,  6,  4,  2, 10,  9,  6],\n",
      "        [ 3,  2,  8, 10,  3, 10,  9],\n",
      "        [ 1,  7,  8,  7,  1,  2,  6],\n",
      "        [ 3,  3,  8,  5,  7, 10, 10],\n",
      "        [ 9,  3,  2,  1,  3, 10,  5]]) tensor([[ 8,  3,  1,  3,  9],\n",
      "        [ 6,  2,  7,  3,  3],\n",
      "        [ 4,  8,  8,  8,  2],\n",
      "        [ 2, 10,  7,  5,  1],\n",
      "        [10,  3,  1,  7,  3],\n",
      "        [ 9, 10,  2, 10, 10],\n",
      "        [ 6,  9,  6, 10,  5]]) tensor([[ 8,  3,  1,  3,  9],\n",
      "        [ 6,  2,  7,  3,  3],\n",
      "        [ 4,  8,  8,  8,  2],\n",
      "        [ 2, 10,  7,  5,  1],\n",
      "        [10,  3,  1,  7,  3],\n",
      "        [ 9, 10,  2, 10, 10],\n",
      "        [ 6,  9,  6, 10,  5]])\n",
      "4\n",
      "tensor([[ 8, 10,  7,  5,  9, 10,  2],\n",
      "        [ 2,  6,  9,  7,  1,  4,  5],\n",
      "        [ 7,  3,  6,  5,  1,  3,  2],\n",
      "        [ 9,  2,  9,  6, 10,  5,  8],\n",
      "        [ 5,  8,  1,  3,  7,  1,  8]]) tensor([[ 8,  2,  7,  9,  5],\n",
      "        [10,  6,  3,  2,  8],\n",
      "        [ 7,  9,  6,  9,  1],\n",
      "        [ 5,  7,  5,  6,  3],\n",
      "        [ 9,  1,  1, 10,  7],\n",
      "        [10,  4,  3,  5,  1],\n",
      "        [ 2,  5,  2,  8,  8]]) tensor([[ 8,  2,  7,  9,  5],\n",
      "        [10,  6,  3,  2,  8],\n",
      "        [ 7,  9,  6,  9,  1],\n",
      "        [ 5,  7,  5,  6,  3],\n",
      "        [ 9,  1,  1, 10,  7],\n",
      "        [10,  4,  3,  5,  1],\n",
      "        [ 2,  5,  2,  8,  8]])\n",
      "tensor([[ 1,  8,  1,  9,  9,  4,  9],\n",
      "        [ 2,  3,  3, 10,  7,  9,  3],\n",
      "        [ 5,  2,  7,  5,  8, 10,  6],\n",
      "        [ 1,  7,  8,  7,  1,  2,  6],\n",
      "        [10,  9,  5,  9,  1,  6, 10]]) tensor([[ 1,  2,  5,  1, 10],\n",
      "        [ 8,  3,  2,  7,  9],\n",
      "        [ 1,  3,  7,  8,  5],\n",
      "        [ 9, 10,  5,  7,  9],\n",
      "        [ 9,  7,  8,  1,  1],\n",
      "        [ 4,  9, 10,  2,  6],\n",
      "        [ 9,  3,  6,  6, 10]]) tensor([[ 1,  2,  5,  1, 10],\n",
      "        [ 8,  3,  2,  7,  9],\n",
      "        [ 1,  3,  7,  8,  5],\n",
      "        [ 9, 10,  5,  7,  9],\n",
      "        [ 9,  7,  8,  1,  1],\n",
      "        [ 4,  9, 10,  2,  6],\n",
      "        [ 9,  3,  6,  6, 10]])\n",
      "tensor([[ 9,  3,  2,  1,  3, 10,  5],\n",
      "        [ 8,  6,  1,  9,  3,  6,  9],\n",
      "        [ 2,  9,  2,  4,  7,  6,  5],\n",
      "        [ 2,  3,  9,  7,  1,  3,  4],\n",
      "        [ 3,  3,  8,  5,  7, 10, 10]]) tensor([[ 9,  8,  2,  2,  3],\n",
      "        [ 3,  6,  9,  3,  3],\n",
      "        [ 2,  1,  2,  9,  8],\n",
      "        [ 1,  9,  4,  7,  5],\n",
      "        [ 3,  3,  7,  1,  7],\n",
      "        [10,  6,  6,  3, 10],\n",
      "        [ 5,  9,  5,  4, 10]]) tensor([[ 9,  8,  2,  2,  3],\n",
      "        [ 3,  6,  9,  3,  3],\n",
      "        [ 2,  1,  2,  9,  8],\n",
      "        [ 1,  9,  4,  7,  5],\n",
      "        [ 3,  3,  7,  1,  7],\n",
      "        [10,  6,  6,  3, 10],\n",
      "        [ 5,  9,  5,  4, 10]])\n",
      "tensor([[ 1, 10,  6,  7,  3,  6,  7],\n",
      "        [ 3,  2,  8, 10,  3, 10,  9],\n",
      "        [ 1,  8,  4,  7,  8,  8,  7],\n",
      "        [ 7, 10, 10,  5,  3,  4,  1],\n",
      "        [ 8,  6,  4,  2, 10,  9,  6]]) tensor([[ 1,  3,  1,  7,  8],\n",
      "        [10,  2,  8, 10,  6],\n",
      "        [ 6,  8,  4, 10,  4],\n",
      "        [ 7, 10,  7,  5,  2],\n",
      "        [ 3,  3,  8,  3, 10],\n",
      "        [ 6, 10,  8,  4,  9],\n",
      "        [ 7,  9,  7,  1,  6]]) tensor([[ 1,  3,  1,  7,  8],\n",
      "        [10,  2,  8, 10,  6],\n",
      "        [ 6,  8,  4, 10,  4],\n",
      "        [ 7, 10,  7,  5,  2],\n",
      "        [ 3,  3,  8,  3, 10],\n",
      "        [ 6, 10,  8,  4,  9],\n",
      "        [ 7,  9,  7,  1,  6]])\n"
     ]
    }
   ],
   "source": [
    "loader=DataLoader(data,batch_size=5, shuffle=True)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    for seq,tgt in loader:\n",
    "        seq,tgt = seq.to(device), tgt.to(device)\n",
    "        print(seq,seq.transpose(1,0),seq.transpose(1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(10,9)\n",
    "softmax=torch.nn.Softmax(dim=1)\n",
    "logits = softmax(embedding(torch.tensor([1,2,3,4,9,0,5,6,7,8,8])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just run through each step of what makes a transformer. This will help us better understand what functions we need to write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([97, 19, 28, 15, 63, 22])\n"
     ]
    }
   ],
   "source": [
    "src = torch.randint(100,[6])\n",
    "encoder_layer = torch.nn.TransformerEncoderLayer(d_model = 16, nhead = 4, dim_feedforward = 16, dropout = 0)\n",
    "encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers = 4)\n",
    "encoder_embedding = torch.nn.Embedding(100,16)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we will let the encoder have dropout = 0 so that the model produces a consistent output for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3283,  0.0077,  0.3913,  0.9870,  0.6921,  0.3539, -1.3776,  1.3551,\n",
      "         -0.2632,  0.2011, -1.9349, -0.9768,  1.0233, -0.5457,  0.3402, -1.5817],\n",
      "        [ 1.2455, -0.0666,  1.1090,  0.5991,  0.1802,  1.1465, -1.9347,  1.0548,\n",
      "         -0.5469,  1.0107, -1.6405, -0.8075,  0.2264, -0.3305,  0.1026, -1.3482],\n",
      "        [ 1.1028, -0.3962,  1.3035,  1.0214, -0.2523,  1.2202, -1.2183,  1.0586,\n",
      "         -0.7378,  0.2708, -2.2377, -0.7819,  0.7078, -0.5491,  0.2720, -0.7837],\n",
      "        [ 0.9776, -0.3862,  0.9163,  0.4753,  0.5099,  1.3121, -1.6841,  1.4081,\n",
      "         -0.6459,  0.6655, -1.6363, -0.9853,  0.6782, -0.6420,  0.2881, -1.2512],\n",
      "        [ 1.6680, -0.3225,  0.3550,  0.7286, -0.0035,  0.3544, -1.1634,  1.3554,\n",
      "         -0.4003,  0.1139, -2.0916, -0.8644,  1.4365, -1.0879,  0.5066, -0.5847],\n",
      "        [ 2.0897,  0.1409, -0.0174, -0.3433,  0.2823,  0.4397, -1.3754,  1.0591,\n",
      "         -0.1134, -0.1459, -1.7945, -0.9701,  1.6416, -0.8249,  0.5295, -0.5980]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = encoder_embedding(src)\n",
    "internal_rep = encoder(x)\n",
    "print(internal_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what we have done here. We have taken a list of integers (tokens), mapped it to the embedding space (now a list of vectors), and transformed those vectors using our encoder layers (which are a combination of self-attention and feed-forward networks). Below are the shapes of the data at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src size is: torch.Size([6])\n",
      "embedded input is:  torch.Size([6, 16])\n",
      "encoded input is:  torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "print(\"src size is:\", src.shape)\n",
    "print(\"embedded input is: \",encoder_embedding(src).shape)\n",
    "print(\"encoded input is: \",internal_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we just had an encoder only transformer, we are essentially done. We can take these encoded vectors, and map them to a new token space. Let's try this out by first performing the contraction on the sequence dimension (dim=0), and then on the embedding space (dim=1). We will do this with two-linear projection layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_projection = torch.nn.Linear(6,1)\n",
    "embedding_projection = torch.nn.Linear(16, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this we can now build probabilities that classify our internal representation into two outcomes, to which we will assign probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6231492161750793], [0.37685078382492065]]\n"
     ]
    }
   ],
   "source": [
    "x = embedding_projection(internal_rep)\n",
    "output = token_projection(x.transpose(0,1))\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "print(softmax(output).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
