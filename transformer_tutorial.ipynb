{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short notebook to walk through some of the applications of Transformer neural nets for tokenized analytic data, and demonstrate the functionality of the repo through examples. First let's load in the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import encoder_decoder, encoder_only, decoder_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each architecture does something a little different, roughly, the inputs and outputs look like the following:\n",
    "\n",
    "1. Encoder-Only: [3,4,2,5,...,5,6,3,4,3,3] --> 8\n",
    "2. Decoder-Only: [5,6,3,4,3] --> [5,6,3,4,3,3]\n",
    "3. Encoder-Decoder: [5,6,3,4,3,3] --> [3,4,2,5,1,3,2]\n",
    "\n",
    "In words, this looks like:\n",
    "\n",
    "1. Encoders take a sequence and maps it to a new vector in the embedding space that gets mapped to a single category\n",
    "2. Decoders take a sequence and predict the next token, either unconditionally, or...\n",
    "3. Encoder-Decoder conditions the next token predictino of the decoder layers with an encoder output vector. \n",
    "\n",
    "Obviously, these are all overlappping, and in many ways you can create the same behavior for encoders with decoders and vice-versa (just have the output of encoder map to the next token in the sequence, as opposed to some completely different semantic category). \n",
    "\n",
    "But for historical reasons, we'll keep all three of these architectures distinct as they have been used for different types of token prediction tasks.\n",
    "\n",
    "Let's start with encoder only and \"train\" a neural network to identify the largest token in a sequence -- i.e. effectively implement a MAX function acting on list using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished import\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder.importLibs()\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Class\n",
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        self.sequences = sequences\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.sequences[idx], dtype=torch.long), torch.tensor(self.targets[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 7, 2, 8, 3], [5, 7, 5, 1, 4], [4, 2, 10, 6, 2], [7, 2, 3, 9, 2], [2, 2, 9, 6, 2], [8, 1, 7, 2, 9], [5, 5, 8, 4, 7], [6, 5, 2, 9, 2], [9, 7, 3, 4, 3], [6, 3, 6, 10, 5]]\n"
     ]
    }
   ],
   "source": [
    "seq = []\n",
    "tgt = []\n",
    "import random\n",
    "\n",
    "for i in range(10):\n",
    "    start = []\n",
    "    for j in range(5):\n",
    "        start.append(random.randint(1,10))\n",
    "    seq.append(start)\n",
    "    tgt.append(random.randint(1,20))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = SequenceDataset([[3,4,5]],[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5]) tensor(3)\n",
      "tensor([3, 4, 5]) tensor(3)\n",
      "tensor([3, 4, 5]) tensor(3)\n",
      "tensor([3, 4, 5]) tensor(3)\n",
      "tensor([3, 4, 5]) tensor(3)\n"
     ]
    }
   ],
   "source": [
    "loader=DataLoader(data,batch_size=1, shuffle=True)\n",
    "for epoch in range(5):\n",
    "    for seq,tgt in loader:\n",
    "        seq,tgt = seq.to(device), tgt.to(device)\n",
    "        print(seq[0],tgt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
